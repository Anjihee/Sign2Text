# sign2text_gui.py (ğŸ“ ì™¼ìª½ ì •ë ¬ ê°œì„  + ë²„íŠ¼ ì•„ë˜ ë°°ì¹˜)

import sys
import os
import cv2
import numpy as np
import mediapipe as mp
from collections import deque
from tensorflow.keras.models import load_model
from PIL import Image, ImageFont, ImageDraw
from PyQt5.QtWidgets import (
    QApplication, QLabel, QPushButton, QWidget, QVBoxLayout, QHBoxLayout, QFrame
)
from PyQt5.QtGui import QImage, QPixmap
from PyQt5.QtCore import QTimer, Qt
import platform

# ==== ì„¤ì • ====
SEQ_NAME = "L20"                 # ì‚¬ìš©í•  ì‹œí€€ìŠ¤ ì´ë¦„ (ì˜ˆ: L10, L20, L30â€¦)
WINDOW_SIZE = int(SEQ_NAME[1:])  # ì‹œí€€ìŠ¤ ê¸¸ì´ (ìˆ«ì ë¶€ë¶„)
CONF_THRESH = 0.3
T = 2.5
# ==== ê²½ë¡œ ì„¤ì • ====
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
MODEL_DIR = os.path.join(BASE_DIR, 'models', SEQ_NAME)
model = load_model(os.path.join(MODEL_DIR, 'sign_language_model_normalized.h5'))
label_classes = np.load(os.path.join(MODEL_DIR, 'label_classes.npy'), allow_pickle=True)
X_mean = np.load(os.path.join(MODEL_DIR, 'X_mean.npy'))
X_std = np.load(os.path.join(MODEL_DIR, 'X_std.npy'))
id2label = {i: lbl for i, lbl in enumerate(label_classes)}


# ==== MediaPipe ì„¤ì • ====
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=2,
                    min_detection_confidence=0.7, 
                    min_tracking_confidence=0.7)
mp_drawing = mp.solutions.drawing_utils

try:
    if platform.system() == "Windows":
        font_path = "C:/Windows/Fonts/malgun.ttf"
    else:
        font_path = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
    font = ImageFont.truetype(font_path, 24)
except:
    font = ImageFont.load_default()

# OpenCV ì´ë¯¸ì§€ ìœ„ì— í•œê¸€ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
def draw_text(img, text, pos=(10, 30), color=(0, 0, 0)):
    pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil)
    draw.text(pos, text, font=font, fill=color)
    return cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)

# ëœë“œë§ˆí¬ ì¢Œí‘œë¥¼ base point ëŒ€ë¹„ ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
def extract_rel(lms, W, H):
    if not lms:
        return [0]*42
    pts = [(p.x*W, p.y*H) for p in lms]
    bx, by = pts[0]
    rel = []
    for x, y in pts:
        rel += [x - bx, y - by]
    return rel

# ëœë“œë§ˆí¬ë“¤ ê°„ì˜ ê´€ì ˆ ê°ë„ ê³„ì‹  (ìµœëŒ€ 15ê°œ)
def calc_ang(lms):
    if not lms:
        return [0]*15
    ang = []
    for i in range(len(lms)-2):
        a = np.array([lms[i].x, lms[i].y])
        b = np.array([lms[i+1].x, lms[i+1].y])
        c = np.array([lms[i+2].x, lms[i+2].y])
        ba = a - b
        bc = c - b
        cos = np.dot(ba, bc) / (np.linalg.norm(ba)*np.linalg.norm(bc) + 1e-6)
        ang.append(np.degrees(np.arccos(np.clip(cos, -1, 1))))
    return ang[:15] + [0]*(15 - len(ang))

# GUI ê°œì„ 
class Sign2TextApp(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Sign2Text ì‹¤ì‹œê°„ ìˆ˜ì–´ ì¸ì‹")
        self.setFixedSize(980, 600)
        self.setStyleSheet("background-color: #ffffff; color: black;")

        self.title_label = QLabel("ğŸ§  Sign2Text | ì‹¤ì‹œê°„ ìˆ˜ì–´ ì¸ì‹ ì‹œìŠ¤í…œ")
        self.title_label.setStyleSheet("font-size: 22px; font-weight: bold; color: #333333; margin-bottom: 10px")
        self.title_label.setAlignment(Qt.AlignCenter)

        self.image_label = QLabel()
        self.image_label.setFixedSize(640, 480)
        self.image_label.setFrameShape(QFrame.Box)

        self.status_label = QLabel("ìƒíƒœ: ëŒ€ê¸° ì¤‘")
        self.status_label.setStyleSheet("font-size: 18px; color: #0077cc;")
        self.status_label.setAlignment(Qt.AlignLeft)

        self.result_label = QLabel("ê²°ê³¼:")
        self.result_label.setStyleSheet("font-size: 18px; font-weight: bold; color: #0066aa")
        self.result_label.setAlignment(Qt.AlignLeft)

        self.top3_title = QLabel("Top-3 ì˜ˆì¸¡ ê²°ê³¼")
        self.top3_title.setStyleSheet("font-size: 16px; color: #222222;")
        self.top3_title.setAlignment(Qt.AlignLeft)

        self.top3_label = QLabel("")
        self.top3_label.setStyleSheet("font-size: 14px; color: #444444")
        self.top3_label.setAlignment(Qt.AlignLeft)

        self.start_btn = QPushButton("ìˆ˜ì§‘ ì‹œì‘")
        self.pred_btn = QPushButton("ì˜ˆì¸¡")
        for btn in (self.start_btn, self.pred_btn):
            btn.setFixedWidth(280)
            btn.setStyleSheet(
                "padding: 10px; font-size: 16px; background-color: #007acc; color: white; border-radius: 5px")

        self.start_btn.clicked.connect(self.toggle_collect)
        self.pred_btn.clicked.connect(self.predict_sign)

        info_layout = QVBoxLayout()
        info_layout.setAlignment(Qt.AlignLeft)
        info_layout.setSpacing(6)
        info_layout.addWidget(self.status_label)
        info_layout.addWidget(self.result_label)
        info_layout.addWidget(self.top3_title)
        info_layout.addWidget(self.top3_label)

        button_layout = QVBoxLayout()
        button_layout.addWidget(self.start_btn)
        button_layout.addWidget(self.pred_btn)
        button_layout.setSpacing(10)
        button_layout.setAlignment(Qt.AlignLeft)

        right_layout = QVBoxLayout()
        right_layout.addSpacing(10)  
        right_layout.addLayout(info_layout)
        right_layout.addSpacing(15)   
        right_layout.addSpacing(150)  # â† ë²„íŠ¼ì„ ìœ„ë¡œ ì˜¬ë¦´ ìˆ˜ ìˆìŒ (ì˜ˆ: 180 ~ 200 ì‚¬ì´ë¡œ)
        right_layout.addLayout(button_layout)

        content_layout = QHBoxLayout()
        content_layout.addWidget(self.image_label)
        content_layout.addLayout(right_layout)

        main_layout = QVBoxLayout()
        main_layout.addWidget(self.title_label)
        main_layout.addLayout(content_layout)

        self.setLayout(main_layout)

        self.cap = cv2.VideoCapture(0)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        self.timer = QTimer()
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(30)

        # ê¸°ì¡´ ìƒíƒœë³€ìˆ˜ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ê´€ë¦¬
        self.sequence = deque()
        self.collecting = False
        self.latest_text = ""

    def update_frame(self):
        ret, frame = self.cap.read()
        if not ret:
            return
        frame = cv2.flip(frame, 1)
        H, W = frame.shape[:2]
        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

        left, right = [], []
        if results.multi_hand_landmarks:
            for lm, hd in zip(results.multi_hand_landmarks, results.multi_handedness):
                if hd.classification[0].label == 'Left':
                    left = lm.landmark
                else:
                    right = lm.landmark
                mp_drawing.draw_landmarks(frame, lm, mp_hands.HAND_CONNECTIONS)

        # íŠ¹ì§• ë²¡í„° ìƒì„±
        feats = extract_rel(left, W, H) + extract_rel(right, W, H) + calc_ang(left) + calc_ang(right)
        if self.collecting and any(abs(f) > 1e-6 for f in feats):
            self.sequence.append(feats)

        # ìƒíƒœ í‘œì‹œ
        frame = draw_text(
            frame,
            f"ìƒíƒœ: {'ìˆ˜ì§‘ ì¤‘' if self.collecting else 'ëŒ€ê¸° ì¤‘'} | {len(self.sequence)}/{WINDOW_SIZE}",
            color=(0, 102, 204) if self.collecting else (50, 50, 50)
        )
        img = QImage(frame, frame.shape[1], frame.shape[0], frame.strides[0], QImage.Format_BGR888)
        self.image_label.setPixmap(QPixmap.fromImage(img))

    # ìˆ˜ì§‘ / ì¤‘ì§€
    def toggle_collect(self):
        self.collecting = not self.collecting
        self.sequence.clear()
        self.latest_text = ""
        self.status_label.setText("ìƒíƒœ: ìˆ˜ì§‘ ì¤‘" if self.collecting else "ìƒíƒœ: ëŒ€ê¸° ì¤‘")
        self.start_btn.setText("ìˆ˜ì§‘ ì¤‘ì§€" if self.collecting else "ìˆ˜ì§‘ ì‹œì‘")

    # ì˜ˆì¸¡ ë²„íŠ¼
    def predict_sign(self):
        if len(self.sequence) < WINDOW_SIZE:
            self.result_label.setText("â— ì‹œí€€ìŠ¤ ë¶€ì¡±")
            self.top3_label.setText("")
            return

        seq_arr = np.array(self.sequence, dtype=np.float32)
        n_windows = len(seq_arr) - WINDOW_SIZE + 1
        windows = np.stack([seq_arr[i:i+WINDOW_SIZE] for i in range(n_windows)], axis=0)
        normed = (windows - X_mean) / X_std
        preds = model.predict(normed, verbose=0)

        # ì˜¨ë„ ìŠ¤ì¼€ì¼ë§
        logits = np.log(np.clip(preds, 1e-12, 1.0))
        scaled = np.exp(logits / T)
        preds_T = scaled / np.sum(scaled, axis=1, keepdims=True)

        # ê° ì°½ë³„ ìµœê³  ì ìˆ˜
        window_scores = preds_T.max(axis=1)
        best_idx = window_scores.argmax()
        best_pred = preds_T[best_idx]

        # Top-3 ì¶œë ¥
        top3_idx = best_pred.argsort()[-3:][::-1]
        top3_text = "\n".join([f"{id2label[idx]}: {best_pred[idx]:.2f}" for idx in top3_idx])

        # ë¬¸í„±ê°’ íŒì •
        top1_conf = best_pred[top3_idx[0]]
        self.latest_text = f"{id2label[top3_idx[0]]} ({top1_conf:.2f})" if top1_conf > CONF_THRESH else "â— ì‹ ë¢°ë„ ë¶€ì¡±"

        # ê²°ê³¼ ì¶œë ¥
        self.result_label.setText(f"ê²°ê³¼: {self.latest_text}")
        self.top3_label.setText(top3_text)
        self.sequence.clear()

    def closeEvent(self, event):
        self.cap.release()
        cv2.destroyAllWindows()

if __name__ == '__main__':
    app = QApplication(sys.argv)
    window = Sign2TextApp()
    window.show()
    sys.exit(app.exec_())