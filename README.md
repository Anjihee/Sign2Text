# âœ‹ğŸ“ˆ ë³´ê°• ë°ì´í„° ìƒì„± & ì‹¤ì‹œê°„ ì¸ì‹ ê°œì„ Â 

---

## ë‹´ë‹¹ íŒŒì¼ ë° ì—­í• 

| íŒŒì¼                                      | ë‚˜ì˜ ì£¼ìš” ìˆ˜ì •Â·êµ¬í˜„ í¬ì¸íŠ¸                                                                                                                                                         |
| --------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`src/webcam/webcam_test.py`**         | *w*Â í‚¤ë¡œ ì›¹ìº  í”„ë ˆì„Â â†’ `raw_seq_*.npy`&`norm_seq_*.npy` ìë™ ì €ì¥.<br>Â Â Â· ì €ì¥ ìœ„ì¹˜Â `dataset/augmented_samples/<label>/`<br>Â Â Â· 1Â ì„¸ì…˜ â‰’Â 20Â í”„ë ˆì„, **ë¼ë²¨ë‹¹ 30 ìƒ˜í”Œ** ìˆ˜ì§‘ ê¶Œì¥                     |
| **`src/train_by_seq_aug.py`**           | ë³´ê°• ì‹œí€€ìŠ¤ë¥¼ **ì›ë³¸Â ë°ì´í„°ì™€ í†µí•© í•™ìŠµ**.<br>Â Â Â· `augmented_samples` ìŠ¤ìº” â†’ shape ê²€ì¦ â†’ `np.stack`<br>Â Â Â· ì •ê·œí™” íŒŒë¼ë¯¸í„° ì €ì¥(`X_mean.npy`,Â `X_std.npy`)<br>Â Â Â·Â `EarlyStopping(patience=12)` ë¡œ ì¡°ì • |
| **`src/webcam/realtime_infer_test.py`** | **ìë™ ì˜ˆì¸¡** ë¡œì§ êµ¬í˜„.<br>Â Â Â· ì†ì´ ì‚¬ë¼ì§„Â 2Â ì´ˆ ë’¤ predict â†’ ê²°ê³¼ 4Â ì´ˆ í‘œì‹œÂ /Â ì—…ë°ì´íŠ¸<br>Â Â Â· ì† ì‚¬ë¼ì§„Â 1Â ì´ˆ ë’¤ì—ë§Œ `sequence.clear()` â†’ ê¹œë¹¡ì„ ë¬´ì‹œ                                                        |

---

## ë°ì´í„° ë³´ê°• ì „ì²´ íë¦„

```mermaid
graph TD
A[í•œêµ­ìˆ˜ì–´ì‚¬ì „ ì›ë³¸ ì˜ìƒ] -->|ëª¨ì…˜ ë”°ë¼ ì‹œì—°| B(webcam_test.py)
B -->|w í‚¤ ì €ì¥| C[raw_seq_<label>_n.npy \n (20Ã—114)]
B --> D[norm_seq_<label>_n.npy \n ((raw-Î¼)/Ïƒ)]
C & D --> E[dataset/augmented_samples/<label>/]
E --> F(train_by_seq_aug.py)
```

> **ìˆ˜ì§‘ ì ˆì°¨**
> 1\)Â `python webcam_test.py` ì‹¤í–‰Â â†’Â *s*Â ìˆ˜ì§‘ â†’ ìˆ˜ì–´ ì‹œì—°
> 2\)Â *w*Â ì €ì¥Â (ë¼ë²¨ë‹¹Â â‰ˆ30â€¯íšŒ)
> 3\)Â `train_by_seq_aug.py` ë¡œ í†µí•© í•™ìŠµ
> 4\)Â `realtime_infer_test.py` ë¡œ ì‹¤ì‹œê°„ ê²€ì¦

---

## `webcam_test.py`Â í•µì‹¬ ì½”ë“œ (ë°œì·Œ)

```python
if key == ord('w'):
    save_dir = base_dir/"dataset"/"augmented_samples"/CURRENT_LABEL
    save_dir.mkdir(parents=True, exist_ok=True)
    np.save(save_dir/f"raw_seq_{CURRENT_LABEL}_{cnt}.npy", seq_arr)
    np.save(save_dir/f"norm_seq_{CURRENT_LABEL}_{cnt}.npy", (seq_arr-X_mean)/X_std)
```

---

## `train_by_seq_aug.py`Â í†µí•© ë¡œì§

```python
aug_dir = DATASET_DIR/"augmented_samples"
for label in aug_dir.iterdir():
    for fn in label.glob("norm_seq_*.npy"):
        seq = np.load(fn).squeeze(0)     # (1,20,114) â†’ (20,114)
        if seq.shape == expected_shape:
            X_aug_list.append(seq)
            y_aug_list.append(label.name)
X_normalized = np.concatenate([X_normalized, np.stack(X_aug_list)])
```

---

## ì‹¤ì‹œê°„ ì¸ì‹ ê°œì„ Â â€“Â ì‹œê°„ ê¸°ë°˜ íŠ¸ë¦¬ê±°

| ì´ë²¤íŠ¸            | ë™ì‘                             |
| -------------- | ------------------------------ |
| ì†ì´ ì‚¬ë¼ì§Â **2â€¯s** | `model.predict()` í˜¸ì¶œ           |
| ê²°ê³¼ í‘œì‹œ          | 4â€¯ì´ˆ ë™ì•ˆ í™”ë©´ ìœ ì§€, ì´í›„ ìë™ í´ë¦¬ì–´        |
| ì† ì‚¬ë¼ì§Â **1â€¯s**  | `sequence.clear()`Â â†’ ë‹¤ìŒ ì œìŠ¤ì²˜ ëŒ€ê¸° |

```python
hands_gone_at = None
if gesture_active:
    if not hand_detected:
        hands_gone_at = hands_gone_at or time.time()
    else:
        hands_gone_at = None

# 1Â ì´ˆ ë²„í¼ ë¦¬ì…‹
if gesture_active and hands_gone_at and time.time()-hands_gone_at>=1:
    sequence.clear()
```

---


