# âœ‹ğŸ“ˆ ë³´ê°•(ì¦ê°•) ë°ì´í„° & ì‹¤ì‹œê°„ ì¸ì‹ ê°œì„ 

---

| íŒŒì¼ | ìˆ˜ì • ë° êµ¬í˜„ í¬ì¸íŠ¸ |
|------|-----------------------|
| **`src/webcam/webcam_test.py`** | `w` í‚¤ë¡œ ì›¹ìº  í”„ë ˆì„ â†’ `raw_seq_*.npy`â€†/â€†`norm_seq_*.npy` ìë™ ì €ì¥<br>Â· ì €ì¥ ê²½ë¡œ `dataset/augmented_samples/<label>/` / ë¼ë²¨ë‹¹ **â‰ˆ30ìƒ˜í”Œ** ìˆ˜ì§‘ ê¶Œì¥ |
| **`src/train_by_seq_aug.py`**  | ë³´ê°• ì‹œí€€ìŠ¤ë¥¼ **ì›ë³¸ ë°ì´í„°ì™€ í†µí•© í•™ìŠµ**<br>Â· `augmented_samples` ìŠ¤ìº” â†’ shape ê²€ì¦ í›„ `np.stack`<br>Â· ì •ê·œí™” íŒŒë¼ë¯¸í„° ì €ì¥(`X_mean.npy`,Â `X_std.npy`) & `EarlyStopping(patience=12)` |
| **`src/webcam/realtime_infer_test.py`** | **p í‚¤ ì œê±° â†’ ì™„ì „ ìë™ ì˜ˆì¸¡** ë¡œì§ êµ¬í˜„<br>Â· *ì† ì‚¬ë¼ì§ 2â€¯s â–¶ predict* â†’ ê²°ê³¼ 4â€¯s í‘œì‹œ & ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸<br>Â· *ì† ì‚¬ë¼ì§ 1â€¯s â–¶ sequence.reset()* â†’ ê¹œë¹¡ì„ ë¬´ì‹œ<br>Â· **97~140 line**: ì œìŠ¤ì²˜ ê°ì§€Â·ê²°ê³¼ ì¶œë ¥ í•µì‹¬ (ì•„ë˜ ìƒì„¸) |

---

## 1 Â· ë°ì´í„° ë³´ê°• íë¦„

```mermaid
graph TD
A[í•œêµ­ìˆ˜ì–´ì‚¬ì „ ì›ë³¸ ì˜ìƒ] -->|í•™ìŠµìš© ëª¨ì…˜ ì¸ì‹| B(webcam_test.py)
B -->|w í‚¤ë¡œ ì €ì¥| C[raw_seq_<label>_n.npy (20Ã—114)]
B --> D[norm_seq_<label>_n.npy ((raw - Î¼) / Ïƒ)]
C & D --> E[dataset/augmented_samples/<label>/]
E --> F(train_by_seq_aug.py)
```

### ìˆ˜ì§‘ ì ˆì°¨

1. `python webcam_test.py` â†’ **s** ìˆ˜ì§‘ â†’ ìˆ˜ì–´ ì‹œì—°  
2. **w** ì €ì¥ (ë¼ë²¨ë‹¹ â‰ˆ 30 ìƒ˜í”Œ)  
3. `train_by_seq_aug.py` í•™ìŠµ â†’ `models/L20/â€¦h5` ê°±ì‹  (SEQ_NAMEìœ¼ë¡œ ì‹œí€€ìŠ¤ ì¡°ì • ê°€ëŠ¥)
4. `realtime_infer_test.py` ë¡œ ì‹¤ì‹œê°„ ê²€ì¦  

---

## 2 Â· `webcam_test.py` ë°œì·Œ (ë³´ê°• ì €ì¥)

```python
if key == ord("w"):
    save_dir = base_dir/"dataset"/"augmented_samples"/CURRENT_LABEL
    save_dir.mkdir(parents=True, exist_ok=True)
    np.save(save_dir/f"raw_seq_{CURRENT_LABEL}_{cnt}.npy",  seq_arr)
    np.save(save_dir/f"norm_seq_{CURRENT_LABEL}_{cnt}.npy", (seq_arr-X_mean)/X_std)
```

---

## 3 Â· `train_by_seq_aug.py` í†µí•© ë¡œì§

```python
aug_dir = DATASET_DIR/"augmented_samples"
for label in aug_dir.iterdir():
    for fn in label.glob("norm_seq_*.npy"):
        seq = np.load(fn).squeeze(0)   # (1,20,114) â†’ (20,114)
        if seq.shape == expected_shape:
            X_aug_list.append(seq)
            y_aug_list.append(label.name)
X_normalized = np.concatenate([X_normalized, np.stack(X_aug_list)], axis=0)
y_raw        = np.concatenate([y_raw, np.array(y_aug_list)], axis=0)
```

---

## 4 Â· ì‹¤ì‹œê°„ ì¸ì‹ ê°œì„  (`realtime_infer_test.py`)

### ìë™ ì œìŠ¤ì²˜ ê°ì§€ & ê²°ê³¼ ì¶œë ¥ (ì½”ë“œ 97~140 line)

```python
# â‘  s ë¡œ ìˆ˜ì§‘ ì‹œì‘ â†’ collecting = True
if collecting and hand_detected and not hand_was_detected:
    gesture_active = True           # ì œìŠ¤ì²˜ ì‹œì‘
    sequence.clear()                # ìƒˆ ë²„í¼

# â‘¡ ì œìŠ¤ì²˜ ë™ì•ˆ ì† ì‚¬ë¼ì§€ë©´ ì²« íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë¡
if gesture_active:
    if not hand_detected:
        hands_gone_at = hands_gone_at or time.time()
    else:
        hands_gone_at = None

# â‘¢ hands_gone_at ìœ ì§€ ì‹œê°„ì´ 2 s ì´ìƒ â†’ model.predict()
if collecting and gesture_active and hands_gone_at \
   and time.time() - hands_gone_at >= 2:
    predict()                       # Conv1Dâ€‘BiLSTM ì˜ˆì¸¡
    display_mode  = True            # ê²°ê³¼ 4 s í‘œì‹œ
    display_timer = time.time()

# â‘£ í‘œì‹œ ì¢…ë£Œ(4 s) ë˜ëŠ” ìƒˆ ì† ë“±ì¥ ì‹œ ìµœì‹  ê²°ê³¼ë¡œ ì—…ë°ì´íŠ¸
if display_mode and time.time() - display_timer >= 4:
    display_mode = False
    latest_text  = ""
```

**í•µì‹¬**
* p í‚¤ ì œê±° â†’ ìë™ íƒ€ì„ìŠ¤íƒ¬í”„ íŠ¸ë¦¬ê±° (`hands_gone_at`)
* ê²°ê³¼ ìœ ì§€Â 4â€¯s â†’ ì´í›„ ìƒˆ ì œìŠ¤ì²˜ ì‹œ ì¦‰ì‹œ update
* ì† ì‚¬ë¼ì§ 1â€¯s (`sequence.clear()`) â†’ ë²„í¼ ê¹”ë” ë¦¬ì…‹ (ê¹œë¹¡ì„ ë¬´ì‹œ)

---

## 5 Â· ì‘ì—… ìˆœì„œ

1. í•œêµ­ìˆ˜ì–´ì‚¬ì „ ì˜ìƒ ì‹œì²­ & ëª¨ì…˜ ì—°ìŠµ  
2. **webcam_test.py** â†’ `s` ìˆ˜ì§‘ â†’ `w` ì €ì¥ Ã— 30íšŒ  
3. **train_by_seq_aug.py** ë¡œ í†µí•© í•™ìŠµ  
4. **realtime_infer_test.py** ë¡œ ì‹¤ì‹œê°„ ì„±ëŠ¥ í™•ì¸  

---

## 6 Â· ì°¸ê³ 

* macOS ë‚´ì¥ ì¹´ë©”ë¼ = `VideoCapture(1)` í•„ìš” ê°€ëŠ¥ì„±

