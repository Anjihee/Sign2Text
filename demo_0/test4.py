import os
import cv2
import numpy as np
import mediapipe as mp
from collections import deque
from tensorflow.keras.models import load_model
from PIL import Image, ImageFont, ImageDraw

# ==== ì„¤ì • ====
WINDOW_SIZE = 10      # ëª¨ë¸ì´ í•™ìŠµëœ í”„ë ˆì„ ì°½ í¬ê¸°
CONF_THRESH = 0.3
BASE_DIR    = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR   = os.path.join(BASE_DIR, '../models')

# ==== ëª¨ë¸ ë° ë©”íƒ€ë°ì´í„° ë¡œë“œ ====
model         = load_model(os.path.join(MODEL_DIR, 'sign_language_model_normalized.h5'))
label_classes = np.load(os.path.join(MODEL_DIR, 'label_classes.npy'), allow_pickle=True)
X_mean        = np.load(os.path.join(MODEL_DIR, 'X_mean.npy'))
X_std         = np.load(os.path.join(MODEL_DIR, 'X_std.npy'))
id2label      = {i: lbl for i, lbl in enumerate(label_classes)}

# ==== MediaPipe Hands ì„¤ì • ====
mp_hands   = mp.solutions.hands
hands      = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=2,
    min_detection_confidence=0.7,
    min_tracking_confidence=0.7
)
mp_drawing = mp.solutions.drawing_utils

# ==== ì‹œí€€ìŠ¤ ë²„í¼ & ìƒíƒœ ë³€ìˆ˜ ====
sequence     = deque()   # ë²„í¼: ë¬´ì œí•œìœ¼ë¡œ ìŒ“ì„
collecting   = False
latest_text  = ""

# ==== í•œê¸€ í°íŠ¸ ë¡œë“œ ====
font = ImageFont.truetype("C:/Windows/Fonts/malgun.ttf", 32)

def draw_text(img, text, pos=(10,50), color=(255,255,0)):
    pil  = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil)
    draw.text(pos, text, font=font, fill=color)
    return cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)

def extract_rel(lms, W, H):
    if not lms:
        return [0]*42
    pts = [(p.x*W, p.y*H) for p in lms]
    bx, by = pts[0]
    rel = []
    for x, y in pts:
        rel += [x-bx, y-by]
    return rel

def calc_ang(lms):
    if not lms:
        return [0]*15
    ang = []
    for i in range(len(lms)-2):
        a = np.array([lms[i].x,   lms[i].y])
        b = np.array([lms[i+1].x, lms[i+1].y])
        c = np.array([lms[i+2].x, lms[i+2].y])
        ba = a - b; bc = c - b
        cos = np.dot(ba, bc)/(np.linalg.norm(ba)*np.linalg.norm(bc)+1e-6)
        ang.append(np.degrees(np.arccos(np.clip(cos, -1, 1))))
    return ang[:15] + [0]*(15 - len(ang))

# ==== ì›¹ìº  ì—´ê¸° ====
cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
if not cap.isOpened():
    cap.release()
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨")
        exit(1)

cv2.namedWindow("Sign2Text ì‹¤ì‹œê°„ ìˆ˜ì–´ ì¸ì‹", cv2.WINDOW_NORMAL)
print("s=ìˆ˜ì§‘ ì‹œì‘/ì¤‘ì§€, p=ì˜ˆì¸¡, q=ì¢…ë£Œ")

while True:
    ret, frame = cap.read()
    if not ret:
        continue

    img = cv2.flip(frame, 1)
    H, W = img.shape[:2]
    results = hands.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

    # ì–‘ì† ëœë“œë§ˆí¬
    left, right = [], []
    if results.multi_hand_landmarks:
        for lm, hd in zip(results.multi_hand_landmarks, results.multi_handedness):
            if hd.classification[0].label == 'Left':
                left = lm.landmark
            else:
                right = lm.landmark
            mp_drawing.draw_landmarks(img, lm, mp_hands.HAND_CONNECTIONS)

    # íŠ¹ì§• ë²¡í„° ìƒì„± ë° ìˆ˜ì§‘
    feats = (
        extract_rel(left, W, H) +
        extract_rel(right, W, H) +
        calc_ang(left) +
        calc_ang(right)
    )
    if collecting and sum(abs(f) for f in feats) != 0:
        sequence.append(feats)

    # í™”ë©´ ìƒíƒœ í‘œì‹œ
    status = f"{'ìˆ˜ì§‘ ì¤‘' if collecting else 'ëŒ€ê¸° ì¤‘'} | seq_len={len(sequence)}"
    img = draw_text(img, status)
    if latest_text:
        img = draw_text(img, f"ê²°ê³¼: {latest_text}", pos=(10,100))

    cv2.imshow("Sign2Text ì‹¤ì‹œê°„ ìˆ˜ì–´ ì¸ì‹", img)

    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break

    elif key == ord('s'):
        collecting = not collecting
        if collecting:
            sequence.clear()
            latest_text = ""
            print("ğŸ”˜ ìˆ˜ì§‘ ì‹œì‘")
        else:
            print("ğŸ”˜ ìˆ˜ì§‘ ì¤‘ì§€")

    elif key == ord('p'):
        if len(sequence) >= WINDOW_SIZE:
            seq_arr   = np.array(sequence)
            n_windows = len(seq_arr) - WINDOW_SIZE + 1

            # ë°°ì¹˜ ìœˆë„ìš° ìƒì„±
            windows = np.stack([
                seq_arr[i:i+WINDOW_SIZE]
                for i in range(n_windows)
            ], axis=0)
            normed = (windows - X_mean) / X_std
            preds  = model.predict(normed, verbose=0)

            # ìµœì  ìœˆë„ìš° ì„ íƒ
            win_idx   = preds.max(axis=1).argmax()
            best_pred = preds[win_idx]
            class_idx = best_pred.argmax()
            best_conf = best_pred[class_idx]

            if best_conf > CONF_THRESH:
                latest_text = f"{id2label[class_idx]} ({best_conf:.2f})"
                print("ğŸ” ì˜ˆì¸¡ ê²°ê³¼:", latest_text)
            else:
                print(f"â— ì‹ ë¢°ë„ ë¶€ì¡±: {best_conf:.2f}")

            # ì˜ˆì¸¡ í›„ ì „ì²´ ë²„í¼ ë¹„ìš°ê¸°
            sequence.clear()
        else:
            print(f"â— ì‹œí€€ìŠ¤ ê¸¸ì´ ë¶€ì¡±: {len(sequence)}/{WINDOW_SIZE}")

cap.release()
cv2.destroyAllWindows()
